digraph {
	graph [size="115.35,115.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4786574960 [label="
 (1, 4)" fillcolor=darkolivegreen1]
	4786136752 [label=AddmmBackward0]
	4786136992 -> 4786136752
	4786289408 [label="value_net.5.bias
 (4)" fillcolor=lightblue]
	4786289408 -> 4786136992
	4786136992 [label=AccumulateGrad]
	4786136896 -> 4786136752
	4786136896 [label=AddmmBackward0]
	4786136848 -> 4786136896
	4786289248 [label="value_net.4.bias
 (256)" fillcolor=lightblue]
	4786289248 -> 4786136848
	4786136848 [label=AccumulateGrad]
	4786136800 -> 4786136896
	4786136800 [label=ReshapeAliasBackward0]
	4786137136 -> 4786136800
	4786137136 [label=ReluBackward0]
	4786137328 -> 4786137136
	4786137328 [label=NativeBatchNormBackward0]
	4786137424 -> 4786137328
	4786137424 [label=ConvolutionBackward0]
	4786137616 -> 4786137424
	4786137616 [label=ReluBackward0]
	4786137760 -> 4786137616
	4786137760 [label=AddBackward0]
	4786137856 -> 4786137760
	4786137856 [label=NativeBatchNormBackward0]
	4786138000 -> 4786137856
	4786138000 [label=ConvolutionBackward0]
	4786138192 -> 4786138000
	4786138192 [label=ReluBackward0]
	4786138336 -> 4786138192
	4786138336 [label=NativeBatchNormBackward0]
	4786138432 -> 4786138336
	4786138432 [label=ConvolutionBackward0]
	4786137808 -> 4786138432
	4786137808 [label=ReluBackward0]
	4786138720 -> 4786137808
	4786138720 [label=AddBackward0]
	4786138816 -> 4786138720
	4786138816 [label=NativeBatchNormBackward0]
	4786138960 -> 4786138816
	4786138960 [label=ConvolutionBackward0]
	4786139152 -> 4786138960
	4786139152 [label=ReluBackward0]
	4786139296 -> 4786139152
	4786139296 [label=NativeBatchNormBackward0]
	4786139392 -> 4786139296
	4786139392 [label=ConvolutionBackward0]
	4786138768 -> 4786139392
	4786138768 [label=ReluBackward0]
	4786139680 -> 4786138768
	4786139680 [label=AddBackward0]
	4786139776 -> 4786139680
	4786139776 [label=NativeBatchNormBackward0]
	4786139920 -> 4786139776
	4786139920 [label=ConvolutionBackward0]
	4786140112 -> 4786139920
	4786140112 [label=ReluBackward0]
	4786140256 -> 4786140112
	4786140256 [label=NativeBatchNormBackward0]
	4786140304 -> 4786140256
	4786140304 [label=ConvolutionBackward0]
	4786140592 -> 4786140304
	4786140592 [label=ReluBackward0]
	4786140736 -> 4786140592
	4786140736 [label=AddBackward0]
	4786140784 -> 4786140736
	4786140784 [label=NativeBatchNormBackward0]
	4786141024 -> 4786140784
	4786141024 [label=ConvolutionBackward0]
	4786141216 -> 4786141024
	4786141216 [label=ReluBackward0]
	4786141360 -> 4786141216
	4786141360 [label=NativeBatchNormBackward0]
	4786141408 -> 4786141360
	4786141408 [label=ConvolutionBackward0]
	4786140640 -> 4786141408
	4786140640 [label=ReluBackward0]
	4786141792 -> 4786140640
	4786141792 [label=AddBackward0]
	4786141840 -> 4786141792
	4786141840 [label=NativeBatchNormBackward0]
	4786142080 -> 4786141840
	4786142080 [label=ConvolutionBackward0]
	4786142272 -> 4786142080
	4786142272 [label=ReluBackward0]
	4786142416 -> 4786142272
	4786142416 [label=NativeBatchNormBackward0]
	4786142464 -> 4786142416
	4786142464 [label=ConvolutionBackward0]
	4786141600 -> 4786142464
	4786141600 [label=ReluBackward0]
	4786142848 -> 4786141600
	4786142848 [label=AddBackward0]
	4786142896 -> 4786142848
	4786142896 [label=NativeBatchNormBackward0]
	4786143136 -> 4786142896
	4786143136 [label=ConvolutionBackward0]
	4786634912 -> 4786143136
	4786634912 [label=ReluBackward0]
	4786635056 -> 4786634912
	4786635056 [label=NativeBatchNormBackward0]
	4786635104 -> 4786635056
	4786635104 [label=ConvolutionBackward0]
	4786142656 -> 4786635104
	4786142656 [label=ReluBackward0]
	4786635488 -> 4786142656
	4786635488 [label=AddBackward0]
	4786635536 -> 4786635488
	4786635536 [label=NativeBatchNormBackward0]
	4786635776 -> 4786635536
	4786635776 [label=ConvolutionBackward0]
	4786635968 -> 4786635776
	4786635968 [label=ReluBackward0]
	4786636112 -> 4786635968
	4786636112 [label=NativeBatchNormBackward0]
	4786636160 -> 4786636112
	4786636160 [label=ConvolutionBackward0]
	4786635296 -> 4786636160
	4786635296 [label=ReluBackward0]
	4786636544 -> 4786635296
	4786636544 [label=AddBackward0]
	4786636592 -> 4786636544
	4786636592 [label=NativeBatchNormBackward0]
	4786636832 -> 4786636592
	4786636832 [label=ConvolutionBackward0]
	4786637024 -> 4786636832
	4786637024 [label=ReluBackward0]
	4786637168 -> 4786637024
	4786637168 [label=NativeBatchNormBackward0]
	4786637216 -> 4786637168
	4786637216 [label=ConvolutionBackward0]
	4786636352 -> 4786637216
	4786636352 [label=ReluBackward0]
	4786637600 -> 4786636352
	4786637600 [label=AddBackward0]
	4786637648 -> 4786637600
	4786637648 [label=NativeBatchNormBackward0]
	4786637888 -> 4786637648
	4786637888 [label=ConvolutionBackward0]
	4786638080 -> 4786637888
	4786638080 [label=ReluBackward0]
	4786638224 -> 4786638080
	4786638224 [label=NativeBatchNormBackward0]
	4786638272 -> 4786638224
	4786638272 [label=ConvolutionBackward0]
	4786638560 -> 4786638272
	4786638560 [label=ReluBackward0]
	4786638704 -> 4786638560
	4786638704 [label=AddBackward0]
	4786638752 -> 4786638704
	4786638752 [label=NativeBatchNormBackward0]
	4786638992 -> 4786638752
	4786638992 [label=ConvolutionBackward0]
	4786639184 -> 4786638992
	4786639184 [label=ReluBackward0]
	4786639328 -> 4786639184
	4786639328 [label=NativeBatchNormBackward0]
	4786639376 -> 4786639328
	4786639376 [label=ConvolutionBackward0]
	4786638608 -> 4786639376
	4786638608 [label=ReluBackward0]
	4786639760 -> 4786638608
	4786639760 [label=AddBackward0]
	4786639808 -> 4786639760
	4786639808 [label=NativeBatchNormBackward0]
	4786640048 -> 4786639808
	4786640048 [label=ConvolutionBackward0]
	4786640240 -> 4786640048
	4786640240 [label=ReluBackward0]
	4786640384 -> 4786640240
	4786640384 [label=NativeBatchNormBackward0]
	4786640432 -> 4786640384
	4786640432 [label=ConvolutionBackward0]
	4786639568 -> 4786640432
	4786639568 [label=ReluBackward0]
	4786640816 -> 4786639568
	4786640816 [label=AddBackward0]
	4786640864 -> 4786640816
	4786640864 [label=NativeBatchNormBackward0]
	4786641104 -> 4786640864
	4786641104 [label=ConvolutionBackward0]
	4786641296 -> 4786641104
	4786641296 [label=ReluBackward0]
	4786641440 -> 4786641296
	4786641440 [label=NativeBatchNormBackward0]
	4786641488 -> 4786641440
	4786641488 [label=ConvolutionBackward0]
	4786640624 -> 4786641488
	4786640624 [label=ReluBackward0]
	4786641872 -> 4786640624
	4786641872 [label=AddBackward0]
	4786641920 -> 4786641872
	4786641920 [label=NativeBatchNormBackward0]
	4786642160 -> 4786641920
	4786642160 [label=ConvolutionBackward0]
	4786642352 -> 4786642160
	4786642352 [label=ReluBackward0]
	4786642496 -> 4786642352
	4786642496 [label=NativeBatchNormBackward0]
	4786642544 -> 4786642496
	4786642544 [label=ConvolutionBackward0]
	4786642832 -> 4786642544
	4786642832 [label=ReluBackward0]
	4786642976 -> 4786642832
	4786642976 [label=AddBackward0]
	4786643024 -> 4786642976
	4786643024 [label=NativeBatchNormBackward0]
	4786643264 -> 4786643024
	4786643264 [label=ConvolutionBackward0]
	4786643456 -> 4786643264
	4786643456 [label=ReluBackward0]
	4786643600 -> 4786643456
	4786643600 [label=NativeBatchNormBackward0]
	4786643648 -> 4786643600
	4786643648 [label=ConvolutionBackward0]
	4786642880 -> 4786643648
	4786642880 [label=ReluBackward0]
	4786644032 -> 4786642880
	4786644032 [label=AddBackward0]
	4786644080 -> 4786644032
	4786644080 [label=NativeBatchNormBackward0]
	4786644320 -> 4786644080
	4786644320 [label=ConvolutionBackward0]
	4786644512 -> 4786644320
	4786644512 [label=ReluBackward0]
	4786644656 -> 4786644512
	4786644656 [label=NativeBatchNormBackward0]
	4786644704 -> 4786644656
	4786644704 [label=ConvolutionBackward0]
	4786643840 -> 4786644704
	4786643840 [label=ReluBackward0]
	4786645088 -> 4786643840
	4786645088 [label=AddBackward0]
	4786645136 -> 4786645088
	4786645136 [label=NativeBatchNormBackward0]
	4786645376 -> 4786645136
	4786645376 [label=ConvolutionBackward0]
	4786645568 -> 4786645376
	4786645568 [label=ReluBackward0]
	4786645712 -> 4786645568
	4786645712 [label=NativeBatchNormBackward0]
	4786645760 -> 4786645712
	4786645760 [label=ConvolutionBackward0]
	4786644896 -> 4786645760
	4786644896 [label=ReluBackward0]
	4786646144 -> 4786644896
	4786646144 [label=NativeBatchNormBackward0]
	4786646192 -> 4786646144
	4786646192 [label=ConvolutionBackward0]
	4786646480 -> 4786646192
	4786101744 [label="conv0.0.weight
 (64, 8, 5, 5)" fillcolor=lightblue]
	4786101744 -> 4786646480
	4786646480 [label=AccumulateGrad]
	4786645952 -> 4786646144
	4786101824 [label="conv0.1.weight
 (64)" fillcolor=lightblue]
	4786101824 -> 4786645952
	4786645952 [label=AccumulateGrad]
	4786646288 -> 4786646144
	4786101904 [label="conv0.1.bias
 (64)" fillcolor=lightblue]
	4786101904 -> 4786646288
	4786646288 [label=AccumulateGrad]
	4786646048 -> 4786645760
	4786102464 [label="layer0.0.residual_function.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	4786102464 -> 4786646048
	4786646048 [label=AccumulateGrad]
	4786645616 -> 4786645712
	4786102544 [label="layer0.0.residual_function.1.weight
 (64)" fillcolor=lightblue]
	4786102544 -> 4786645616
	4786645616 [label=AccumulateGrad]
	4786645856 -> 4786645712
	4786102624 [label="layer0.0.residual_function.1.bias
 (64)" fillcolor=lightblue]
	4786102624 -> 4786645856
	4786645856 [label=AccumulateGrad]
	4786645520 -> 4786645376
	4786103024 [label="layer0.0.residual_function.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	4786103024 -> 4786645520
	4786645520 [label=AccumulateGrad]
	4786645328 -> 4786645136
	4786103104 [label="layer0.0.residual_function.4.weight
 (64)" fillcolor=lightblue]
	4786103104 -> 4786645328
	4786645328 [label=AccumulateGrad]
	4786645280 -> 4786645136
	4786103184 [label="layer0.0.residual_function.4.bias
 (64)" fillcolor=lightblue]
	4786103184 -> 4786645280
	4786645280 [label=AccumulateGrad]
	4786644896 -> 4786645088
	4786644992 -> 4786644704
	4786103664 [label="layer0.1.residual_function.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	4786103664 -> 4786644992
	4786644992 [label=AccumulateGrad]
	4786644560 -> 4786644656
	4786103744 [label="layer0.1.residual_function.1.weight
 (64)" fillcolor=lightblue]
	4786103744 -> 4786644560
	4786644560 [label=AccumulateGrad]
	4786644800 -> 4786644656
	4786103824 [label="layer0.1.residual_function.1.bias
 (64)" fillcolor=lightblue]
	4786103824 -> 4786644800
	4786644800 [label=AccumulateGrad]
	4786644464 -> 4786644320
	4786104304 [label="layer0.1.residual_function.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	4786104304 -> 4786644464
	4786644464 [label=AccumulateGrad]
	4786644272 -> 4786644080
	4786104384 [label="layer0.1.residual_function.4.weight
 (64)" fillcolor=lightblue]
	4786104384 -> 4786644272
	4786644272 [label=AccumulateGrad]
	4786644224 -> 4786644080
	4786104464 [label="layer0.1.residual_function.4.bias
 (64)" fillcolor=lightblue]
	4786104464 -> 4786644224
	4786644224 [label=AccumulateGrad]
	4786643840 -> 4786644032
	4786643936 -> 4786643648
	4786104944 [label="layer0.2.residual_function.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	4786104944 -> 4786643936
	4786643936 [label=AccumulateGrad]
	4786643504 -> 4786643600
	4786105024 [label="layer0.2.residual_function.1.weight
 (64)" fillcolor=lightblue]
	4786105024 -> 4786643504
	4786643504 [label=AccumulateGrad]
	4786643744 -> 4786643600
	4786105104 [label="layer0.2.residual_function.1.bias
 (64)" fillcolor=lightblue]
	4786105104 -> 4786643744
	4786643744 [label=AccumulateGrad]
	4786643408 -> 4786643264
	4786105584 [label="layer0.2.residual_function.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	4786105584 -> 4786643408
	4786643408 [label=AccumulateGrad]
	4786643216 -> 4786643024
	4786105664 [label="layer0.2.residual_function.4.weight
 (64)" fillcolor=lightblue]
	4786105664 -> 4786643216
	4786643216 [label=AccumulateGrad]
	4786643168 -> 4786643024
	4786105744 [label="layer0.2.residual_function.4.bias
 (64)" fillcolor=lightblue]
	4786105744 -> 4786643168
	4786643168 [label=AccumulateGrad]
	4786642880 -> 4786642976
	4786642784 -> 4786642544
	4786106224 [label="layer1.0.residual_function.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	4786106224 -> 4786642784
	4786642784 [label=AccumulateGrad]
	4786642400 -> 4786642496
	4786106304 [label="layer1.0.residual_function.1.weight
 (128)" fillcolor=lightblue]
	4786106304 -> 4786642400
	4786642400 [label=AccumulateGrad]
	4786642640 -> 4786642496
	4786106384 [label="layer1.0.residual_function.1.bias
 (128)" fillcolor=lightblue]
	4786106384 -> 4786642640
	4786642640 [label=AccumulateGrad]
	4786642304 -> 4786642160
	4786106864 [label="layer1.0.residual_function.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	4786106864 -> 4786642304
	4786642304 [label=AccumulateGrad]
	4786642112 -> 4786641920
	4786106944 [label="layer1.0.residual_function.4.weight
 (128)" fillcolor=lightblue]
	4786106944 -> 4786642112
	4786642112 [label=AccumulateGrad]
	4786642064 -> 4786641920
	4786107024 [label="layer1.0.residual_function.4.bias
 (128)" fillcolor=lightblue]
	4786107024 -> 4786642064
	4786642064 [label=AccumulateGrad]
	4786641680 -> 4786641872
	4786641680 [label=NativeBatchNormBackward0]
	4786642736 -> 4786641680
	4786642736 [label=ConvolutionBackward0]
	4786642832 -> 4786642736
	4786643120 -> 4786642736
	4786107504 [label="layer1.0.shortcut.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	4786107504 -> 4786643120
	4786643120 [label=AccumulateGrad]
	4786642256 -> 4786641680
	4786107584 [label="layer1.0.shortcut.1.weight
 (128)" fillcolor=lightblue]
	4786107584 -> 4786642256
	4786642256 [label=AccumulateGrad]
	4786642208 -> 4786641680
	4786107664 [label="layer1.0.shortcut.1.bias
 (128)" fillcolor=lightblue]
	4786107664 -> 4786642208
	4786642208 [label=AccumulateGrad]
	4786641776 -> 4786641488
	4786108144 [label="layer1.1.residual_function.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	4786108144 -> 4786641776
	4786641776 [label=AccumulateGrad]
	4786641344 -> 4786641440
	4786108224 [label="layer1.1.residual_function.1.weight
 (128)" fillcolor=lightblue]
	4786108224 -> 4786641344
	4786641344 [label=AccumulateGrad]
	4786641584 -> 4786641440
	4786108304 [label="layer1.1.residual_function.1.bias
 (128)" fillcolor=lightblue]
	4786108304 -> 4786641584
	4786641584 [label=AccumulateGrad]
	4786641248 -> 4786641104
	4786108784 [label="layer1.1.residual_function.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	4786108784 -> 4786641248
	4786641248 [label=AccumulateGrad]
	4786641056 -> 4786640864
	4786108864 [label="layer1.1.residual_function.4.weight
 (128)" fillcolor=lightblue]
	4786108864 -> 4786641056
	4786641056 [label=AccumulateGrad]
	4786641008 -> 4786640864
	4786108944 [label="layer1.1.residual_function.4.bias
 (128)" fillcolor=lightblue]
	4786108944 -> 4786641008
	4786641008 [label=AccumulateGrad]
	4786640624 -> 4786640816
	4786640720 -> 4786640432
	4786109424 [label="layer1.2.residual_function.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	4786109424 -> 4786640720
	4786640720 [label=AccumulateGrad]
	4786640288 -> 4786640384
	4786109504 [label="layer1.2.residual_function.1.weight
 (128)" fillcolor=lightblue]
	4786109504 -> 4786640288
	4786640288 [label=AccumulateGrad]
	4786640528 -> 4786640384
	4786109584 [label="layer1.2.residual_function.1.bias
 (128)" fillcolor=lightblue]
	4786109584 -> 4786640528
	4786640528 [label=AccumulateGrad]
	4786640192 -> 4786640048
	4786110064 [label="layer1.2.residual_function.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	4786110064 -> 4786640192
	4786640192 [label=AccumulateGrad]
	4786640000 -> 4786639808
	4786110144 [label="layer1.2.residual_function.4.weight
 (128)" fillcolor=lightblue]
	4786110144 -> 4786640000
	4786640000 [label=AccumulateGrad]
	4786639952 -> 4786639808
	4786110224 [label="layer1.2.residual_function.4.bias
 (128)" fillcolor=lightblue]
	4786110224 -> 4786639952
	4786639952 [label=AccumulateGrad]
	4786639568 -> 4786639760
	4786639664 -> 4786639376
	4786274608 [label="layer1.3.residual_function.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	4786274608 -> 4786639664
	4786639664 [label=AccumulateGrad]
	4786639232 -> 4786639328
	4786274688 [label="layer1.3.residual_function.1.weight
 (128)" fillcolor=lightblue]
	4786274688 -> 4786639232
	4786639232 [label=AccumulateGrad]
	4786639472 -> 4786639328
	4786274768 [label="layer1.3.residual_function.1.bias
 (128)" fillcolor=lightblue]
	4786274768 -> 4786639472
	4786639472 [label=AccumulateGrad]
	4786639136 -> 4786638992
	4786275248 [label="layer1.3.residual_function.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	4786275248 -> 4786639136
	4786639136 [label=AccumulateGrad]
	4786638944 -> 4786638752
	4786275328 [label="layer1.3.residual_function.4.weight
 (128)" fillcolor=lightblue]
	4786275328 -> 4786638944
	4786638944 [label=AccumulateGrad]
	4786638896 -> 4786638752
	4786275408 [label="layer1.3.residual_function.4.bias
 (128)" fillcolor=lightblue]
	4786275408 -> 4786638896
	4786638896 [label=AccumulateGrad]
	4786638608 -> 4786638704
	4786638512 -> 4786638272
	4786275888 [label="layer2.0.residual_function.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	4786275888 -> 4786638512
	4786638512 [label=AccumulateGrad]
	4786638128 -> 4786638224
	4786275968 [label="layer2.0.residual_function.1.weight
 (256)" fillcolor=lightblue]
	4786275968 -> 4786638128
	4786638128 [label=AccumulateGrad]
	4786638368 -> 4786638224
	4786276048 [label="layer2.0.residual_function.1.bias
 (256)" fillcolor=lightblue]
	4786276048 -> 4786638368
	4786638368 [label=AccumulateGrad]
	4786638032 -> 4786637888
	4786276528 [label="layer2.0.residual_function.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	4786276528 -> 4786638032
	4786638032 [label=AccumulateGrad]
	4786637840 -> 4786637648
	4786276608 [label="layer2.0.residual_function.4.weight
 (256)" fillcolor=lightblue]
	4786276608 -> 4786637840
	4786637840 [label=AccumulateGrad]
	4786637792 -> 4786637648
	4786276688 [label="layer2.0.residual_function.4.bias
 (256)" fillcolor=lightblue]
	4786276688 -> 4786637792
	4786637792 [label=AccumulateGrad]
	4786637408 -> 4786637600
	4786637408 [label=NativeBatchNormBackward0]
	4786638464 -> 4786637408
	4786638464 [label=ConvolutionBackward0]
	4786638560 -> 4786638464
	4786638656 -> 4786638464
	4786277168 [label="layer2.0.shortcut.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	4786277168 -> 4786638656
	4786638656 [label=AccumulateGrad]
	4786637984 -> 4786637408
	4786277248 [label="layer2.0.shortcut.1.weight
 (256)" fillcolor=lightblue]
	4786277248 -> 4786637984
	4786637984 [label=AccumulateGrad]
	4786637936 -> 4786637408
	4786277328 [label="layer2.0.shortcut.1.bias
 (256)" fillcolor=lightblue]
	4786277328 -> 4786637936
	4786637936 [label=AccumulateGrad]
	4786637504 -> 4786637216
	4786277728 [label="layer2.1.residual_function.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	4786277728 -> 4786637504
	4786637504 [label=AccumulateGrad]
	4786637072 -> 4786637168
	4786277808 [label="layer2.1.residual_function.1.weight
 (256)" fillcolor=lightblue]
	4786277808 -> 4786637072
	4786637072 [label=AccumulateGrad]
	4786637312 -> 4786637168
	4786277888 [label="layer2.1.residual_function.1.bias
 (256)" fillcolor=lightblue]
	4786277888 -> 4786637312
	4786637312 [label=AccumulateGrad]
	4786636976 -> 4786636832
	4786278368 [label="layer2.1.residual_function.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	4786278368 -> 4786636976
	4786636976 [label=AccumulateGrad]
	4786636784 -> 4786636592
	4786278448 [label="layer2.1.residual_function.4.weight
 (256)" fillcolor=lightblue]
	4786278448 -> 4786636784
	4786636784 [label=AccumulateGrad]
	4786636736 -> 4786636592
	4786278528 [label="layer2.1.residual_function.4.bias
 (256)" fillcolor=lightblue]
	4786278528 -> 4786636736
	4786636736 [label=AccumulateGrad]
	4786636352 -> 4786636544
	4786636448 -> 4786636160
	4786279008 [label="layer2.2.residual_function.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	4786279008 -> 4786636448
	4786636448 [label=AccumulateGrad]
	4786636016 -> 4786636112
	4786279088 [label="layer2.2.residual_function.1.weight
 (256)" fillcolor=lightblue]
	4786279088 -> 4786636016
	4786636016 [label=AccumulateGrad]
	4786636256 -> 4786636112
	4786279168 [label="layer2.2.residual_function.1.bias
 (256)" fillcolor=lightblue]
	4786279168 -> 4786636256
	4786636256 [label=AccumulateGrad]
	4786635920 -> 4786635776
	4786279648 [label="layer2.2.residual_function.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	4786279648 -> 4786635920
	4786635920 [label=AccumulateGrad]
	4786635728 -> 4786635536
	4786279728 [label="layer2.2.residual_function.4.weight
 (256)" fillcolor=lightblue]
	4786279728 -> 4786635728
	4786635728 [label=AccumulateGrad]
	4786635680 -> 4786635536
	4786279808 [label="layer2.2.residual_function.4.bias
 (256)" fillcolor=lightblue]
	4786279808 -> 4786635680
	4786635680 [label=AccumulateGrad]
	4786635296 -> 4786635488
	4786635392 -> 4786635104
	4786280288 [label="layer2.3.residual_function.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	4786280288 -> 4786635392
	4786635392 [label=AccumulateGrad]
	4786634960 -> 4786635056
	4786280368 [label="layer2.3.residual_function.1.weight
 (256)" fillcolor=lightblue]
	4786280368 -> 4786634960
	4786634960 [label=AccumulateGrad]
	4786635200 -> 4786635056
	4786280448 [label="layer2.3.residual_function.1.bias
 (256)" fillcolor=lightblue]
	4786280448 -> 4786635200
	4786635200 [label=AccumulateGrad]
	4786634864 -> 4786143136
	4786280928 [label="layer2.3.residual_function.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	4786280928 -> 4786634864
	4786634864 [label=AccumulateGrad]
	4786143088 -> 4786142896
	4786281008 [label="layer2.3.residual_function.4.weight
 (256)" fillcolor=lightblue]
	4786281008 -> 4786143088
	4786143088 [label=AccumulateGrad]
	4786143040 -> 4786142896
	4786281088 [label="layer2.3.residual_function.4.bias
 (256)" fillcolor=lightblue]
	4786281088 -> 4786143040
	4786143040 [label=AccumulateGrad]
	4786142656 -> 4786142848
	4786142752 -> 4786142464
	4786281568 [label="layer2.4.residual_function.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	4786281568 -> 4786142752
	4786142752 [label=AccumulateGrad]
	4786142320 -> 4786142416
	4786281648 [label="layer2.4.residual_function.1.weight
 (256)" fillcolor=lightblue]
	4786281648 -> 4786142320
	4786142320 [label=AccumulateGrad]
	4786142560 -> 4786142416
	4786281728 [label="layer2.4.residual_function.1.bias
 (256)" fillcolor=lightblue]
	4786281728 -> 4786142560
	4786142560 [label=AccumulateGrad]
	4786142224 -> 4786142080
	4786282208 [label="layer2.4.residual_function.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	4786282208 -> 4786142224
	4786142224 [label=AccumulateGrad]
	4786142032 -> 4786141840
	4786282288 [label="layer2.4.residual_function.4.weight
 (256)" fillcolor=lightblue]
	4786282288 -> 4786142032
	4786142032 [label=AccumulateGrad]
	4786141984 -> 4786141840
	4786282368 [label="layer2.4.residual_function.4.bias
 (256)" fillcolor=lightblue]
	4786282368 -> 4786141984
	4786141984 [label=AccumulateGrad]
	4786141600 -> 4786141792
	4786141696 -> 4786141408
	4786282848 [label="layer2.5.residual_function.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	4786282848 -> 4786141696
	4786141696 [label=AccumulateGrad]
	4786141264 -> 4786141360
	4786282928 [label="layer2.5.residual_function.1.weight
 (256)" fillcolor=lightblue]
	4786282928 -> 4786141264
	4786141264 [label=AccumulateGrad]
	4786141504 -> 4786141360
	4786283008 [label="layer2.5.residual_function.1.bias
 (256)" fillcolor=lightblue]
	4786283008 -> 4786141504
	4786141504 [label=AccumulateGrad]
	4786141168 -> 4786141024
	4786283488 [label="layer2.5.residual_function.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	4786283488 -> 4786141168
	4786141168 [label=AccumulateGrad]
	4786140976 -> 4786140784
	4786283568 [label="layer2.5.residual_function.4.weight
 (256)" fillcolor=lightblue]
	4786283568 -> 4786140976
	4786140976 [label=AccumulateGrad]
	4786140928 -> 4786140784
	4786283648 [label="layer2.5.residual_function.4.bias
 (256)" fillcolor=lightblue]
	4786283648 -> 4786140928
	4786140928 [label=AccumulateGrad]
	4786140640 -> 4786140736
	4786140544 -> 4786140304
	4786284128 [label="layer3.0.residual_function.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	4786284128 -> 4786140544
	4786140544 [label=AccumulateGrad]
	4786140160 -> 4786140256
	4786284208 [label="layer3.0.residual_function.1.weight
 (512)" fillcolor=lightblue]
	4786284208 -> 4786140160
	4786140160 [label=AccumulateGrad]
	4786140400 -> 4786140256
	4786284288 [label="layer3.0.residual_function.1.bias
 (512)" fillcolor=lightblue]
	4786284288 -> 4786140400
	4786140400 [label=AccumulateGrad]
	4786140064 -> 4786139920
	4786284768 [label="layer3.0.residual_function.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	4786284768 -> 4786140064
	4786140064 [label=AccumulateGrad]
	4786139872 -> 4786139776
	4786284848 [label="layer3.0.residual_function.4.weight
 (512)" fillcolor=lightblue]
	4786284848 -> 4786139872
	4786139872 [label=AccumulateGrad]
	4786139824 -> 4786139776
	4786284928 [label="layer3.0.residual_function.4.bias
 (512)" fillcolor=lightblue]
	4786284928 -> 4786139824
	4786139824 [label=AccumulateGrad]
	4786139728 -> 4786139680
	4786139728 [label=NativeBatchNormBackward0]
	4786140496 -> 4786139728
	4786140496 [label=ConvolutionBackward0]
	4786140592 -> 4786140496
	4786140880 -> 4786140496
	4786285408 [label="layer3.0.shortcut.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	4786285408 -> 4786140880
	4786140880 [label=AccumulateGrad]
	4786140016 -> 4786139728
	4786285488 [label="layer3.0.shortcut.1.weight
 (512)" fillcolor=lightblue]
	4786285488 -> 4786140016
	4786140016 [label=AccumulateGrad]
	4786139968 -> 4786139728
	4786285568 [label="layer3.0.shortcut.1.bias
 (512)" fillcolor=lightblue]
	4786285568 -> 4786139968
	4786139968 [label=AccumulateGrad]
	4786139584 -> 4786139392
	4786286048 [label="layer3.1.residual_function.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	4786286048 -> 4786139584
	4786139584 [label=AccumulateGrad]
	4786139344 -> 4786139296
	4786286128 [label="layer3.1.residual_function.1.weight
 (512)" fillcolor=lightblue]
	4786286128 -> 4786139344
	4786139344 [label=AccumulateGrad]
	4786139200 -> 4786139296
	4786286208 [label="layer3.1.residual_function.1.bias
 (512)" fillcolor=lightblue]
	4786286208 -> 4786139200
	4786139200 [label=AccumulateGrad]
	4786139104 -> 4786138960
	4786286688 [label="layer3.1.residual_function.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	4786286688 -> 4786139104
	4786139104 [label=AccumulateGrad]
	4786138912 -> 4786138816
	4786286768 [label="layer3.1.residual_function.4.weight
 (512)" fillcolor=lightblue]
	4786286768 -> 4786138912
	4786138912 [label=AccumulateGrad]
	4786138864 -> 4786138816
	4786286848 [label="layer3.1.residual_function.4.bias
 (512)" fillcolor=lightblue]
	4786286848 -> 4786138864
	4786138864 [label=AccumulateGrad]
	4786138768 -> 4786138720
	4786138624 -> 4786138432
	4786287328 [label="layer3.2.residual_function.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	4786287328 -> 4786138624
	4786138624 [label=AccumulateGrad]
	4786138384 -> 4786138336
	4786287408 [label="layer3.2.residual_function.1.weight
 (512)" fillcolor=lightblue]
	4786287408 -> 4786138384
	4786138384 [label=AccumulateGrad]
	4786138240 -> 4786138336
	4786287488 [label="layer3.2.residual_function.1.bias
 (512)" fillcolor=lightblue]
	4786287488 -> 4786138240
	4786138240 [label=AccumulateGrad]
	4786138144 -> 4786138000
	4786287968 [label="layer3.2.residual_function.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	4786287968 -> 4786138144
	4786138144 [label=AccumulateGrad]
	4786137952 -> 4786137856
	4786288048 [label="layer3.2.residual_function.4.weight
 (512)" fillcolor=lightblue]
	4786288048 -> 4786137952
	4786137952 [label=AccumulateGrad]
	4786137904 -> 4786137856
	4786288128 [label="layer3.2.residual_function.4.bias
 (512)" fillcolor=lightblue]
	4786288128 -> 4786137904
	4786137904 [label=AccumulateGrad]
	4786137808 -> 4786137760
	4786137568 -> 4786137424
	4786288608 [label="value_net.0.weight
 (4, 512, 3, 3)" fillcolor=lightblue]
	4786288608 -> 4786137568
	4786137568 [label=AccumulateGrad]
	4786137376 -> 4786137328
	4786288688 [label="value_net.1.weight
 (4)" fillcolor=lightblue]
	4786288688 -> 4786137376
	4786137376 [label=AccumulateGrad]
	4786137232 -> 4786137328
	4786288768 [label="value_net.1.bias
 (4)" fillcolor=lightblue]
	4786288768 -> 4786137232
	4786137232 [label=AccumulateGrad]
	4786136608 -> 4786136896
	4786136608 [label=TBackward0]
	4786137472 -> 4786136608
	4786289168 [label="value_net.4.weight
 (256, 1156)" fillcolor=lightblue]
	4786289168 -> 4786137472
	4786137472 [label=AccumulateGrad]
	4786136944 -> 4786136752
	4786136944 [label=TBackward0]
	4786138048 -> 4786136944
	4786289328 [label="value_net.5.weight
 (4, 256)" fillcolor=lightblue]
	4786289328 -> 4786138048
	4786138048 [label=AccumulateGrad]
	4786136752 -> 4786574960
	4786575360 [label="
 (1, 136)" fillcolor=darkolivegreen1]
	4786137040 [label=AddmmBackward0]
	4786137520 -> 4786137040
	4786290208 [label="policy_net.4.bias
 (136)" fillcolor=lightblue]
	4786290208 -> 4786137520
	4786137520 [label=AccumulateGrad]
	4786137184 -> 4786137040
	4786137184 [label=ReshapeAliasBackward0]
	4786137664 -> 4786137184
	4786137664 [label=ReluBackward0]
	4786138480 -> 4786137664
	4786138480 [label=NativeBatchNormBackward0]
	4786139008 -> 4786138480
	4786139008 [label=ConvolutionBackward0]
	4786137616 -> 4786139008
	4786139536 -> 4786139008
	4786289568 [label="policy_net.0.weight
 (2, 512, 3, 3)" fillcolor=lightblue]
	4786289568 -> 4786139536
	4786139536 [label=AccumulateGrad]
	4786138288 -> 4786138480
	4786289648 [label="policy_net.1.weight
 (2)" fillcolor=lightblue]
	4786289648 -> 4786138288
	4786138288 [label=AccumulateGrad]
	4786138096 -> 4786138480
	4786289728 [label="policy_net.1.bias
 (2)" fillcolor=lightblue]
	4786289728 -> 4786138096
	4786138096 [label=AccumulateGrad]
	4786137280 -> 4786137040
	4786137280 [label=TBackward0]
	4786138528 -> 4786137280
	4786290128 [label="policy_net.4.weight
 (136, 578)" fillcolor=lightblue]
	4786290128 -> 4786138528
	4786138528 [label=AccumulateGrad]
	4786137040 -> 4786575360
}
